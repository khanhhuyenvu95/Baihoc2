import streamlit as st
import pandas as pd
import numpy as np
import json
from google import genai
from google.genai.errors import APIError
from typing import Dict, Any, Optional
# C·∫ßn c√†i ƒë·∫∑t th∆∞ vi·ªán python-docx ƒë·ªÉ ƒë·ªçc file .docx: pip install python-docx
# Do h·∫°n ch·∫ø v·ªÅ m√¥i tr∆∞·ªùng, ch√∫ng ta s·∫Ω h∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng c√†i ƒë·∫∑t
# v√† s·ª≠ d·ª•ng th∆∞ vi·ªán n√†y ƒë·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file Word.
try:
    from docx import Document
except ImportError:
    st.warning("‚ö†Ô∏è Vui l√≤ng ch·∫°y l·ªánh 'pip install python-docx' ƒë·ªÉ Streamlit c√≥ th·ªÉ ƒë·ªçc n·ªôi dung file Word.")

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="·ª®ng d·ª•ng ƒê√°nh gi√° Ph∆∞∆°ng √°n Kinh doanh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng ƒê√°nh gi√° Ph∆∞∆°ng √°n ƒê·∫ßu t∆∞ D·ª± √°n üìä")
st.caption("S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh t·ª´ file Word v√† ph√¢n t√≠ch hi·ªáu qu·∫£ d·ª± √°n.")

# Kh√≥a API
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")

# --- H√†m 1: Tr√≠ch xu·∫•t D·ªØ li·ªáu T√†i ch√≠nh b·∫±ng AI ---
def extract_financial_data(file_buffer: bytes, api_key: str) -> Optional[Dict[str, Any]]:
    """ƒê·ªçc file Word, tr√≠ch xu·∫•t vƒÉn b·∫£n v√† g·ª≠i ƒë·∫øn Gemini ƒë·ªÉ l·ªçc d·ªØ li·ªáu theo c·∫•u tr√∫c JSON."""
    try:
        # 1. ƒê·ªçc n·ªôi dung file Word
        with open("temp_upload.docx", "wb") as f:
            f.write(file_buffer)
        
        doc = Document("temp_upload.docx")
        text_content = "\n".join([paragraph.text for paragraph in doc.paragraphs if paragraph.text.strip()])
        
        if not text_content:
            st.error("N·ªôi dung file Word tr·ªëng. Vui l√≤ng ki·ªÉm tra file.")
            return None

        # 2. C·∫•u h√¨nh AI Client v√† Model
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash'

        # 3. ƒê·ªãnh nghƒ©a Y√™u c·∫ßu v√† Schema JSON
        system_prompt = (
            "B·∫°n l√† tr·ª£ l√Ω tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc k·ªπ vƒÉn b·∫£n ƒë∆∞·ª£c cung c·∫•p "
            "v√† tr√≠ch xu·∫•t 6 th√¥ng s·ªë t√†i ch√≠nh ch√≠nh x√°c nh·∫•t. ƒê∆°n v·ªã trong vƒÉn b·∫£n l√† t·ª∑ ƒë·ªìng (n·∫øu c√≥), "
            "h√£y chuy·ªÉn ch√∫ng th√†nh s·ªë th·∫≠p ph√¢n. WACC v√† Thu·∫ø su·∫•t ph·∫£i l√† s·ªë th·∫≠p ph√¢n (v√≠ d·ª•: 0.13 ho·∫∑c 0.2)."
        )

        response_schema = {
            "type": "OBJECT",
            "properties": {
                "v·ªën_ƒë·∫ßu_t∆∞": {"type": "NUMBER", "description": "T·ªïng V·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu (VND, s·ªë th·∫≠p ph√¢n)"},
                "v√≤ng_ƒë·ªùi_d·ª±_√°n": {"type": "INTEGER", "description": "V√≤ng ƒë·ªùi d·ª± √°n (s·ªë nƒÉm)"},
                "doanh_thu_h√†ng_nƒÉm": {"type": "NUMBER", "description": "Doanh thu c·ªë ƒë·ªãnh h√†ng nƒÉm (VND, s·ªë th·∫≠p ph√¢n)"},
                "chi_ph√≠_h√†ng_nƒÉm": {"type": "NUMBER", "description": "Chi ph√≠ ho·∫°t ƒë·ªông c·ªë ƒë·ªãnh h√†ng nƒÉm (VND, s·ªë th·∫≠p ph√¢n)"},
                "wacc": {"type": "NUMBER", "description": "Chi ph√≠ v·ªën b√¨nh qu√¢n (WACC), d∆∞·ªõi d·∫°ng s·ªë th·∫≠p ph√¢n (v√≠ d·ª•: 0.13 cho 13%)"},
                "thu·∫ø_su·∫•t": {"type": "NUMBER", "description": "Thu·∫ø su·∫•t thu nh·∫≠p doanh nghi·ªáp, d∆∞·ªõi d·∫°ng s·ªë th·∫≠p ph√¢n (v√≠ d·ª•: 0.2 cho 20%)"}
            },
            "required": ["v·ªën_ƒë·∫ßu_t∆∞", "v√≤ng_ƒë·ªùi_d·ª±_√°n", "doanh_thu_h√†ng_nƒÉm", "chi_ph√≠_h√†ng_nƒÉm", "wacc", "thu·∫ø_su·∫•t"]
        }

        user_query = f"Tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh t·ª´ vƒÉn b·∫£n sau v√† tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng JSON:\n\n---\n\n{text_content}"
        
        # 4. G·ªçi API
        response = client.models.generate_content(
            model=model_name,
            contents=user_query,
            system_instruction=types.SystemInstruction(parts=[types.Part.from_text(system_prompt)]),
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=response_schema
            )
        )
        
        # 5. Ph√¢n t√≠ch k·∫øt qu·∫£
        json_string = response.text.strip()
        data = json.loads(json_string)
        
        # Chuy·ªÉn ƒë·ªïi ƒë∆°n v·ªã (Gi·∫£ ƒë·ªãnh ƒë·∫ßu v√†o file l√† T·ª∑ VND, chuy·ªÉn v·ªÅ VND)
        # N·∫øu ƒë√£ y√™u c·∫ßu AI tr·∫£ v·ªÅ s·ªë nguy√™n VND, b∆∞·ªõc n√†y kh√¥ng c·∫ßn.
        # Gi·ªØ nguy√™n gi√° tr·ªã AI tr√≠ch xu·∫•t (th∆∞·ªùng l√† ƒë∆°n v·ªã nh·ªè nh·∫•t, vd: VND)
        return data

    except APIError as e:
        st.error(f"L·ªói g·ªçi Gemini API: {e}. Vui l√≤ng ki·ªÉm tra Kh√≥a API.")
        return None
    except Exception as e:
        st.error(f"L·ªói khi tr√≠ch xu·∫•t ho·∫∑c ph√¢n t√≠ch JSON: {e}")
        st.info("Ki·ªÉm tra l·∫°i ƒë·ªãnh d·∫°ng v√† n·ªôi dung file Word, ƒë·∫£m b·∫£o c√°c s·ªë li·ªáu r√µ r√†ng.")
        return None

# --- H√†m 2 & 3: X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn v√† T√≠nh Ch·ªâ s·ªë ---
@st.cache_data(show_spinner=False)
def calculate_financial_metrics(data: Dict[str, float]) -> Dict[str, Any]:
    """X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn v√† t√≠nh NPV, IRR, PP, DPP."""
    I0 = data['v·ªën_ƒë·∫ßu_t∆∞']
    N = int(data['v√≤ng_ƒë·ªùi_d·ª±_√°n'])
    R = data['doanh_thu_h√†ng_nƒÉm']
    C = data['chi_ph√≠_h√†ng_nƒÉm']
    WACC = data['wacc']
    Tau = data['thu·∫ø_su·∫•t']

    # 1. T√≠nh to√°n c∆° b·∫£n
    EBIT = R - C
    Khau_hao = I0 / N # Gi·∫£ ƒë·ªãnh kh·∫•u hao ƒë·ªÅu, gi√° tr·ªã thanh l√Ω = 0
    
    # D√≤ng ti·ªÅn thu·∫ßn h√†ng nƒÉm (NCF)
    EAT = EBIT * (1 - Tau)
    NCF_annual = EAT + Khau_hao

    # 2. X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn (Cash Flow Table)
    years = list(range(0, N + 1))
    
    # D√≤ng ti·ªÅn ra ban ƒë·∫ßu (NƒÉm 0)
    CF_list = [-I0]
    
    # D√≤ng ti·ªÅn v√†o h√†ng nƒÉm (NƒÉm 1 ƒë·∫øn N)
    NCF_list = [NCF_annual] * N
    CF_list.extend(NCF_list) 

    # H·ªá s·ªë chi·∫øt kh·∫•u (Discount Factor)
    Discount_factors = [1 / ((1 + WACC) ** t) for t in years]

    # D√≤ng ti·ªÅn chi·∫øt kh·∫•u (Discounted Cash Flow - DCF)
    DCF_list = [CF_list[t] * Discount_factors[t] for t in years]

    # D√≤ng ti·ªÅn t√≠ch l≈©y (Cumulative Cash Flow - CCF)
    CCF_list = np.cumsum(CF_list).tolist()
    
    # D√≤ng ti·ªÅn chi·∫øt kh·∫•u t√≠ch l≈©y (Cumulative Discounted Cash Flow - CDCF)
    CDCF_list = np.cumsum(DCF_list).tolist()

    # T·∫°o DataFrame
    df_cf = pd.DataFrame({
        'NƒÉm': years,
        'D√≤ng ti·ªÅn (CF)': CF_list,
        'H·ªá s·ªë chi·∫øt kh·∫•u': Discount_factors,
        'D√≤ng ti·ªÅn chi·∫øt kh·∫•u (DCF)': DCF_list,
        'D√≤ng ti·ªÅn t√≠ch l≈©y (CCF)': CCF_list,
        'D√≤ng ti·ªÅn chi·∫øt kh·∫•u t√≠ch l≈©y (CDCF)': CDCF_list,
    })

    # 3. T√≠nh Ch·ªâ s·ªë ƒê√°nh gi√°
    
    # NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn)
    # np.npv y√™u c·∫ßu su·∫•t chi·∫øt kh·∫•u v√† danh s√°ch d√≤ng ti·ªÅn t·ª´ nƒÉm 1 tr·ªü ƒëi.
    NPV = np.npv(WACC, NCF_list) + CF_list[0] 

    # IRR (T·ª∑ su·∫•t ho√†n v·ªën n·ªôi b·ªô)
    IRR = np.irr(CF_list) 

    # PP (Th·ªùi gian ho√†n v·ªën)
    # T√¨m nƒÉm cu·ªëi c√πng CCF < 0
    payback_year = next((i - 1 for i, ccf in enumerate(CCF_list) if ccf > 0), N)
    
    if payback_year < N and NCF_list[0] != 0:
        PP = payback_year + abs(CCF_list[payback_year]) / NCF_list[0]
    else:
        PP = float('inf') # D·ª± √°n kh√¥ng ho√†n v·ªën trong v√≤ng ƒë·ªùi

    # DPP (Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u)
    # T∆∞∆°ng t·ª± PP, s·ª≠ d·ª•ng CDCF
    discounted_payback_year = next((i - 1 for i, cdcf in enumerate(CDCF_list) if cdcf > 0), N)
    
    if discounted_payback_year < N and DCF_list[discounted_payback_year + 1] != 0:
        DPP = discounted_payback_year + abs(CDCF_list[discounted_payback_year]) / DCF_list[discounted_payback_year + 1]
    else:
        DPP = float('inf')

    # 4. K·∫øt qu·∫£
    results = {
        'df_cf': df_cf,
        'NPV': NPV,
        'IRR': IRR,
        'PP': PP,
        'DPP': DPP,
        'WACC': WACC,
        'N': N
    }
    return results

# --- H√†m 4: Ph√¢n t√≠ch Ch·ªâ s·ªë b·∫±ng AI ---
def get_ai_analysis_metrics(analysis_data: Dict[str, Any], api_key: str) -> str:
    """Y√™u c·∫ßu AI ph√¢n t√≠ch c√°c ch·ªâ s·ªë NPV, IRR, PP, DPP."""
    try:
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash'
        
        # Chuy·ªÉn ƒë·ªïi ch·ªâ s·ªë th√†nh chu·ªói th√¢n thi·ªán v·ªõi AI
        wacc_percent = f"{analysis_data['WACC'] * 100:.2f}%"
        irr_percent = f"{analysis_data['IRR'] * 100:.2f}%"
        npv_value = f"{analysis_data['NPV']:,.0f}"
        
        prompt = f"""
        B·∫°n l√† m·ªôt Chuy√™n gia Th·∫©m ƒë·ªãnh D·ª± √°n Kinh doanh. D∆∞·ªõi ƒë√¢y l√† c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ t√†i ch√≠nh c·ªßa m·ªôt d·ª± √°n ƒë·∫ßu t∆∞ c√≥ v√≤ng ƒë·ªùi {analysis_data['N']} nƒÉm.
        
        Th√¥ng s·ªë:
        - WACC (Chi ph√≠ v·ªën): {wacc_percent}
        - NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn): {npv_value} VND
        - IRR (T·ª∑ su·∫•t ho√†n v·ªën n·ªôi b·ªô): {irr_percent}
        - PP (Th·ªùi gian ho√†n v·ªën tƒ©nh): {analysis_data['PP']:.2f} nƒÉm
        - DPP (Th·ªùi gian ho√†n v·ªën chi·∫øt kh·∫•u): {analysis_data['DPP']:.2f} nƒÉm
        
        H√£y ph√¢n t√≠ch c√°c ch·ªâ s·ªë tr√™n v√† ƒë∆∞a ra nh·∫≠n x√©t chuy√™n s√¢u, k·∫øt lu·∫≠n v·ªÅ t√≠nh kh·∫£ thi c·ªßa d·ª± √°n.
        1. ƒê√°nh gi√° NPV: D·ª± √°n c√≥ t·∫°o ra gi√° tr·ªã gia tƒÉng kh√¥ng?
        2. ƒê√°nh gi√° IRR so v·ªõi WACC: D·ª± √°n c√≥ hi·ªáu qu·∫£ h∆°n chi ph√≠ v·ªën kh√¥ng?
        3. ƒê√°nh gi√° PP v√† DPP: D·ª± √°n c√≥ r·ªßi ro v·ªÅ thanh kho·∫£n kh√¥ng?
        4. K·∫øt lu·∫≠n cu·ªëi c√πng: Khuy·∫øn ngh·ªã ch·∫•p nh·∫≠n hay t·ª´ ch·ªëi ƒë·∫ßu t∆∞.
        """

        response = client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        return response.text

    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: {e}. Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng."
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh trong qu√° tr√¨nh ph√¢n t√≠ch AI: {e}"


# --- Ch·ª©c nƒÉng 1: T·∫£i File v√† L·ªçc D·ªØ li·ªáu ---
st.subheader("1. T·∫£i l√™n v√† L·ªçc D·ªØ li·ªáu D·ª± √°n")
uploaded_file = st.file_uploader(
    "T·∫£i file Word (.docx) ch·ª©a Ph∆∞∆°ng √°n Kinh doanh",
    type=['docx']
)

if uploaded_file and GEMINI_API_KEY:
    # N√∫t b·∫•m ƒë·ªÉ th·ª±c hi·ªán thao t√°c l·ªçc d·ªØ li·ªáu
    if st.button("üîç L·ªçc D·ªØ li·ªáu T√†i ch√≠nh b·∫±ng AI"):
        st.session_state.extraction_data = None
        st.session_state.analysis_results = None
        
        with st.spinner('ƒêang tr√≠ch xu·∫•t vƒÉn b·∫£n v√† g·ª≠i ƒë·∫øn Gemini AI...'):
            # ƒê·ªçc file buffer ƒë·ªÉ truy·ªÅn v√†o h√†m
            file_buffer = uploaded_file.read()
            # Th·ª±c hi·ªán tr√≠ch xu·∫•t
            data = extract_financial_data(file_buffer, GEMINI_API_KEY)

        if data:
            st.success("‚úÖ Tr√≠ch xu·∫•t d·ªØ li·ªáu th√†nh c√¥ng!")
            st.session_state.extraction_data = data
            
            st.markdown("##### üìå C√°c Th√¥ng s·ªë D·ª± √°n ƒë√£ ƒë∆∞·ª£c AI L·ªçc:")
            
            data_display = pd.DataFrame({
                "Ch·ªâ ti√™u": [
                    "V·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu ($I_0$)", 
                    "V√≤ng ƒë·ªùi d·ª± √°n (NƒÉm)", 
                    "Doanh thu h√†ng nƒÉm ($R$)", 
                    "Chi ph√≠ h√†ng nƒÉm ($C$)", 
                    "WACC", 
                    "Thu·∫ø su·∫•t ($\\tau$)"
                ],
                "Gi√° tr·ªã": [
                    f"{data['v·ªën_ƒë·∫ßu_t∆∞']:,.0f}", 
                    f"{data['v√≤ng_ƒë·ªùi_d·ª±_√°n']}", 
                    f"{data['doanh_thu_h√†ng_nƒÉm']:,.0f}", 
                    f"{data['chi_ph√≠_h√†ng_nƒÉm']:,.0f}", 
                    f"{data['wacc'] * 100:.2f}%", 
                    f"{data['thu·∫ø_su·∫•t'] * 100:.2f}%"
                ]
            })
            st.dataframe(data_display, hide_index=True, use_container_width=True)


# --- Ch·ª©c nƒÉng 2 & 3: B·∫£ng D√≤ng Ti·ªÅn v√† Ch·ªâ s·ªë ƒê√°nh gi√° ---
if 'extraction_data' in st.session_state and st.session_state.extraction_data is not None:
    data = st.session_state.extraction_data
    
    try:
        # T√≠nh to√°n t·∫•t c·∫£ c√°c ch·ªâ s·ªë v√† b·∫£ng d√≤ng ti·ªÅn
        results = calculate_financial_metrics(data)
        st.session_state.analysis_results = results
        
        # 2. X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn
        st.subheader("2. B·∫£ng D√≤ng Ti·ªÅn (Cash Flow Table)")
        
        # Hi·ªÉn th·ªã b·∫£ng d√≤ng ti·ªÅn
        st.dataframe(results['df_cf'].style.format({
            'D√≤ng ti·ªÅn (CF)': '{:,.0f}',
            'H·ªá s·ªë chi·∫øt kh·∫•u': '{:.4f}',
            'D√≤ng ti·ªÅn chi·∫øt kh·∫•u (DCF)': '{:,.0f}',
            'D√≤ng ti·ªÅn t√≠ch l≈©y (CCF)': '{:,.0f}',
            'D√≤ng ti·ªÅn chi·∫øt kh·∫•u t√≠ch l≈©y (CDCF)': '{:,.0f}',
        }), hide_index=True, use_container_width=True)
        
        
        # 3. T√≠nh to√°n c√°c ch·ªâ s·ªë ƒë√°nh gi√° hi·ªáu qu·∫£ d·ª± √°n
        st.subheader("3. C√°c Ch·ªâ s·ªë ƒê√°nh gi√° Hi·ªáu qu·∫£ D·ª± √°n")
        
        col_npv, col_irr, col_pp, col_dpp = st.columns(4)
        
        with col_npv:
            # M√†u s·∫Øc d·ª±a tr√™n NPV (NPV > 0 -> success, NPV < 0 -> error)
            npv_status = "success" if results['NPV'] > 0 else "error"
            st.metric(
                label="Gi√° tr·ªã Hi·ªán t·∫°i Thu·∫ßn (NPV)",
                value=f"{results['NPV']:,.0f} VND",
                delta="Kh·∫£ thi" if results['NPV'] > 0 else "Kh√¥ng kh·∫£ thi"
            )
        
        with col_irr:
            # M√†u s·∫Øc d·ª±a tr√™n IRR so v·ªõi WACC
            irr_status = "success" if results['IRR'] > results['WACC'] else "error"
            st.metric(
                label="T·ª∑ su·∫•t Ho√†n v·ªën N·ªôi b·ªô (IRR)",
                value=f"{results['IRR'] * 100:.2f}%",
                delta_color=irr_status,
                delta=f"WACC: {results['WACC'] * 100:.2f}%"
            )

        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ho√†n v·ªën v√¥ h·∫°n (Inf)
        pp_display = "Kh√¥ng ho√†n v·ªën" if results['PP'] == float('inf') else f"{results['PP']:.2f} nƒÉm"
        dpp_display = "Kh√¥ng ho√†n v·ªën" if results['DPP'] == float('inf') else f"{results['DPP']:.2f} nƒÉm"

        with col_pp:
            st.metric(label="Th·ªùi gian Ho√†n v·ªën Tƒ©nh (PP)", value=pp_display)
        with col_dpp:
            st.metric(label="Th·ªùi gian Ho√†n v·ªën Chi·∫øt kh·∫•u (DPP)", value=dpp_display)

    except Exception as e:
        st.error(f"L·ªói khi t√≠nh to√°n ch·ªâ s·ªë t√†i ch√≠nh: {e}")
        st.info("Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c AI tr√≠ch xu·∫•t (v√≠ d·ª•: WACC, Thu·∫ø su·∫•t c√≥ ph·∫£i l√† s·ªë th·∫≠p ph√¢n kh√¥ng).")


# --- Ch·ª©c nƒÉng 4: Ph√¢n t√≠ch c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n ---
if 'analysis_results' in st.session_state and st.session_state.analysis_results is not None:
    
    st.markdown("---")
    st.subheader("4. Ph√¢n t√≠ch Chuy√™n s√¢u v·ªÅ Hi·ªáu qu·∫£ D·ª± √°n (AI)")
    
    if st.button("ü§ñ Y√™u c·∫ßu AI Ph√¢n t√≠ch Ch·ªâ s·ªë Hi·ªáu qu·∫£"):
        
        with st.spinner('ƒêang g·ª≠i c√°c ch·ªâ s·ªë ƒë·∫øn Gemini ƒë·ªÉ nh·∫≠n nh·∫≠n x√©t...'):
            ai_analysis = get_ai_analysis_metrics(st.session_state.analysis_results, GEMINI_API_KEY)
            
            st.markdown("#### **K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Chuy√™n gia T√†i ch√≠nh AI:**")
            st.info(ai_analysis)

elif not GEMINI_API_KEY:
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")

elif uploaded_file is None:
    st.info("Vui l√≤ng t·∫£i l√™n file Word v√† nh·∫•n n√∫t 'L·ªçc D·ªØ li·ªáu T√†i ch√≠nh b·∫±ng AI' ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
